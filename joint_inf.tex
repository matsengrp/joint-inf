\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\graphicspath{ {figures/} }

% Commands
\newcommand{\alphabet}{\mathcal{A}}
\newcommand{\fullAlignment}{\mathbf{Y}}
\newcommand{\alignmentColumn}{\mathbf{y}}
\newcommand{\sitePattern}{s}
\newcommand{\fullSitePatterns}{\mathbf{s}}
\newcommand{\sitePatternSpace}{\mathcal{S}}
\newcommand{\fullAncestralStates}{\mathbf{H}}
\newcommand{\ancestralStateSpace}{\mathcal{H}}
\newcommand{\ancestralStateColumn}{\boldsymbol\eta}
\newcommand{\ancestralStateCategory}{z}
\newcommand{\fullAncestralStateCategories}{\mathbf{z}}
\newcommand{\ancestralStateCategorySpace}{\mathcal{Z}}

\newcommand{\nCols}{n}
\newcommand{\nSiteRows}{m}
\newcommand{\nAncestralStateRows}{p}


\title{Possible Inconsistency in Maximum Likelihood Calculation of Ancestral States}
\author{Shaw, Matsen, Minin}

\begin{document}
\maketitle

%comments from Erick:
% >  This is great!
% > - would be great to have all the calculations showing the "refinement" structure written out for the various tree structures (just done by hand and scanned is just fine)
% > - I think of the "refinement" as a partition, so perhaps rather than "empty refinement" we have a "single-element partition"
% > - in order to interpret the site patterns I need to figure out in what order the leaves are labeled
% > - how is ell calculated?
% > - on the numerical sanity check, it doesn't seem clear that the branch lengths can be different than the inferred ones-- they can!
% > - re "general case", agreed though I don't think that we need numerical optimization of branch lengths in a set of a branch length partition-- we can just get the optimal branch length directly. Namely, for each branch, we know all hidden states (given that we are in a set of a partition) and so can count the number of mutations across that branch. From there we have a simple likelihood function, which either has an optimal in the interior or on the boundary of the partition.

\renewcommand{\arraystretch}{1.2} % because otherwise exponents get eaten by \hline


\section*{Introduction}

Classical maximum-likelihood (ML) estimation in phylogenetics operates by integrating out possible ancestral states at the internal nodes of the tree.
Recently \cite{Neher2017} have suggested using an approximation to ML inference in which the likelihood is maximized jointly across model parameters and ancestral sequences.
This is attractive from a computational perspective: joint ML inference can proceed according to an iterative procedure in which ML ancestral sequences are first inferred and then model parameters are optimized conditional on the ancestral sequences.
% I would say classical maximum likelihood is closer to EM, no? At some point in EM we'd have to marginalize/take the expectation, which joint ML doesn't do. Curious to talk more about it though...
This latter step is much simpler and more computationally efficient when conditioning on ancestral sequences compared to the case in which ancestral sequences are marginalized out.

However, existing consistency proofs for phylogenetics \cite{RoyChoudhury2015-ta} do not apply to the setting of joint inference of trees and ancestral sequences.
There are examples in statistics, such as the Neyman-Scott paradox \cite{Neyman1948-tt}, in which estimation of additional parameters destroys consistency.
This raises the question of whether joint inference of trees and ancestral sequences enjoys good statistical properties.

In this paper we show that the joint inference of trees and ancestral sequences is not consistent in general.
To do so, we follow a strategy of using simple models and four taxa trees.
Here we use a binary symmetric model and simulate on the ``Farris zone'' \cite{Siddall1998-hq} tree.
We use bounds on the joint likelihood to demarcate a sizeable area of long branch lengths in which joint inference converges on the wrong tree.

\section{Ancestral state reconstruction using maximum likelihood}

We will be considering phylogenetic likelihood on unrooted phylogenetic trees.
We assume the character alphabet $\alphabet=\{0,1\}$ and a uniform stationary distribution.
Let $m$ be the number of tips of the tree, and $p = m-2$ the number of internal nodes.
%EM Commented out below because it's not right-- fullAlignment is not the set of assignments of characters to tips of the tree, it's a single such.
%Let $\fullAlignment$ be the set of assignments of characters to tips of our tree, and $\fullAncestralStates$ the set of assignments of characters to the internal nodes of the tree.
Assume we observe $n$ samples of character data (i.e.\ an alignment with $n$ columns) $\fullAlignment=[\alignmentColumn_1,\ldots,\alignmentColumn_n]\in\alphabet^{\nSiteRows\times n}$.
There are also corresponding unknown ancestral states $\fullAncestralStates=[\ancestralStateColumn_1,\ldots,\ancestralStateColumn_n]\in\alphabet^{\nAncestralStateRows\times n}$.

\subsection{Classical maximum-likelihood inference in phylogenetics}

For a topology $\tau$ and branch lengths $t$ we form the fully-observed likelihood (making the usual independence assumption between sites):
\begin{equation}
\label{eq:full_likelihood}
L_n(\fullAlignment;\fullAncestralStates, \tau, t) = \prod_{i=1}^{n} \ P(\alignmentColumn_i, \ancestralStateColumn_i | \tau, t).
\end{equation}
% In particular, we are interested in
% $$
% (\hat{\boldsymbol\xi}, \hat{\tau}, \hat{t}) = \arg\max_{\boldsymbol\xi, \tau, t} \ L_n(\mathbf{y};\boldsymbol\xi, \tau, t),
% $$
% which we call the maximum likelihood values of the parameters $(\boldsymbol\xi, \tau, t)$.
% Since the number of elements in $\boldsymbol\xi$ grows with that of the observed data $\mathbf{y}$,
The typical approach to estimate the tree $\tau$ and branch lengths $t$ involves computing the marginal likelihood
\begin{equation}
\label{eq:marginal_likelihood}
\tilde{L}_n(\fullAlignment; \tau, t) = \sum_{\fullAncestralStates} \ L_n(\fullAlignment;\fullAncestralStates, \tau, t)
\end{equation}
and maximizing over the topology and branch lengths to obtain
$$
(\hat{\tau}, \hat{t}) = \arg\max_{\tau, t} \  \tilde{L}_n(\fullAlignment; \tau, t).
$$
% The values $\hat{\boldsymbol\xi}$ are then calculated conditional on these estimates.
% More likely in practice we fix a topology $\tau$ and use this marginalization approach to compute $(\hat{\boldsymbol\xi}, \hat{t})$.

\subsection{Joint maximization}

One tantalizing approach is to do away with the marginalization and directly estimate the maximum likelihood parameters from the full likelihood in \eqref{eq:full_likelihood}.
We can perform this by computing the profile likelihood
\begin{equation}
\label{eq:profile_likelihood}
L_n'(\fullAlignment;\tau, t) = \max_{\fullAncestralStates} \ L_n(\fullAlignment;\fullAncestralStates, \tau, t),
\end{equation}
then estimating the topology and branch lengths via
\begin{equation}
\label{eq:profile_likelihood_topology_bl}
(\hat{\tau}, \hat{t}) = \arg\max_{\tau, t} \ L_n'(\fullAlignment;\tau, t)
\end{equation}
while using $\hat{\fullAncestralStates}$ maximizing \eqref{eq:profile_likelihood} as an estimate for $\fullAncestralStates$.
Since $\alphabet$ is a discrete set, there exists a maximum \eqref{eq:profile_likelihood}, and so \eqref{eq:profile_likelihood_topology_bl} will recover the joint ML values of the unknown parameters.
In the general case, the functional form of \eqref{eq:profile_likelihood} is determined by inequalities that depend on the unknown $(\tau,t)$.
For this reason, in practice the joint ML strategy estimates $\hat{\fullAncestralStates}$ for a fixed $(\tau,t)$, then $(\hat{\tau},\hat{t})$ given $\hat{\fullAncestralStates}$, maximizing each of these conditional objectives until convergence cite{Neher2017}.

\subsection{Site pattern formulation}

Since we have a finite character alphabet, for a given column $i$ there are a finite number of possibilities of assignments of characters to tips $\alignmentColumn_i$ or internal nodes $\ancestralStateColumn_i$.
These are commonly called ``site patterns'' in the literature.
%EM in general aren't a different number of internal site patterns than tip site patterns?
%das: Yes, I moved the paragraph at the end to here so it's hopefully less confusing. Maybe writing out the example would help? I also changed from "pattern" to "category" which might make it a little more clear.
%EM Seems good this is an important concept so it's worth defining it more properly.
We enumerate the unique site patterns $\mathbf{s}=[s_1,\ldots,s_q]\in\mathcal{S}$; these are defined by the number of leaves and the character alphabet.
Corresponding to each of these site patterns will be an ancestral state category that is most likely given a particular likelihood.
Since $\alphabet$ is a finite set, the value of each factor $P(\alignmentColumn_i, \ancestralStateColumn_i | \tau, t)$ in \eqref{eq:full_likelihood} is maximized at one or more values of $\ancestralStateColumn_i$, though independent of $i$ given $j$.
This independence allows us to group factors by those where $\ancestralStateColumn_i$ belongs to an ancestral state category $\ancestralStateCategory_j$ so that, if $\alignmentColumn_i=\sitePattern_j$ and $\ancestralStateColumn_i\in \ancestralStateCategory_j$, $P(\sitePattern_j, \ancestralStateCategory_j | \tau, t)$ is maximized.

For ancestral state categories $\fullAncestralStateCategories=[\ancestralStateCategory_1,\ldots,\ancestralStateCategory_q]\in\ancestralStateCategorySpace$ we reformulate the likelihood equation
\begin{align}
L_n'(\fullAlignment;\tau, t) &= \max_{\fullAncestralStates} \ L_n(\fullAlignment;\fullAncestralStates, \tau, t) \\
                             &= \max_{\fullAncestralStates} \ \prod_{i=1}^{n} \ P(\alignmentColumn_i, \ancestralStateColumn_i | \tau, t) \\
%EM Can you think a little about z_j?
%EM Even though it's a category now, it's still a function of tau and t, right?
                             &= \max_{\fullAncestralStateCategories} \ \prod_{j=1}^{q} \ P(\sitePattern_j, \ancestralStateCategory_j | \tau, t)^{n_j(\fullAlignment)} \label{eq:site_pattern_likelihood}
\end{align}
where $n_j(\fullAlignment)$ is the number of observations in the sample where site pattern $\sitePattern_j$ was seen in $\fullAlignment$.

\textbf{Example:} This might be a good time for a toy example showing this for a very simple topology.


\subsection{Showing inconsistency}

We are now interested in the properties of the objective function being maximized in \eqref{eq:site_pattern_likelihood} as data becomes plentiful.
Let
$$
L_n''(\fullAlignment;\fullAncestralStateCategories,\tau,t) = \prod_{j=1}^q \ P(\sitePattern_j, \ancestralStateCategory_j | \tau, t)^{n_j(\fullAlignment)}
$$
so that
$$
\max_{\fullAncestralStates} \ L_n(\fullAlignment;\fullAncestralStates, \tau, t) =
    \max_{\fullAncestralStateCategories} \ L_n''(\fullAlignment;\fullAncestralStateCategories,\tau,t).
$$
Assume our $n$ observations were generated from a model with parameters $(\tau^*, t^*)$.
We have
\begin{align}
    \frac{1}{n} \log L_n''(\fullAlignment;\fullAncestralStateCategories,\tau,t)
        &= \sum_{j} \frac{n_j(\fullAlignment)}{n}\cdot  \log P(\sitePattern_j, \ancestralStateCategory_j | \tau, t) \\
        &= \sum_{j} \frac{n_j(\fullAlignment)}{n}\cdot [\log P(\sitePattern_j | \tau, t) + \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)].
\end{align}
In the limit of infinite data we have
$$
\frac{1}{n} \log L_n''(\fullAlignment;,\tau,t) \rightarrow \sum_{j} P(\sitePattern_j | \tau^*, t^*) \cdot [\log P(\sitePattern_j | \tau, t) + \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)]
$$
and that, since $\ancestralStateCategory_j$ appears only in the last term, the log of \eqref{eq:site_pattern_likelihood} in the same limit is proportional to
\begin{align}
\frac{1}{n} \log L_n'(\fullAlignment;\fullAncestralStateCategories,\tau, t)
    &= \max_{\fullAncestralStateCategories} \ \frac{1}{n} \log L_n''(\fullAlignment;\fullAncestralStateCategories,\tau,t) \nonumber \\
    &\rightarrow \max_{\fullAncestralStateCategories} \ \sum_{j} P(\sitePattern_j | \tau^*, t^*) \cdot [\log P(\sitePattern_j | \tau, t) + \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)] \nonumber \\
    &= \max_{\fullAncestralStateCategories} \ \sum_{j} P(\sitePattern_j | \tau^*, t^*) \cdot [\log P(\sitePattern_j | \tau, t) + \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)] \nonumber \\
    &= \max_{\fullAncestralStateCategories} \ \left\{\sum_{j} P(\sitePattern_j | \tau^*, t^*) \cdot \left[\log P(\sitePattern_j | \tau, t) + \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)\right]\right\}. \label{eq:site_pattern_profile_likelihood_mean}
\end{align}
Define the the information quantity
$$
H_{\tau^*,t^*}(\tau,t) = \sum_{j} P(\sitePattern_j | \tau^*, t^*) \log P(\sitePattern_j | \tau, t),
$$
and the partial log likelihood
$$
\ell^p_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t) = \sum_{j} P(\sitePattern_j | \tau^*, t^*) \log P(\ancestralStateCategory_j | \sitePattern_j, \tau, t)
$$
so that \eqref{eq:site_pattern_profile_likelihood_mean} is written as
\begin{equation}
    \label{eq:log_likelihood_simplified}
\ell_{\tau^*,t^*}(\tau,t) = \max_{\fullAncestralStateCategories} \ \left\{H_{\tau^*,t^*}(\tau,t) + \ell^p_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t)\right\}.
\end{equation}
Recall $(\tau, t)$ are estimands and $(\tau^*, t^*)$ are fixed, generating parameters.
For data generated from $(\tau^*, t^*)$, if
\begin{equation}
\label{eq:inconsistency_inequality}
\ell_{\tau^*,t^*}(\tau',\hat{t}_1) > \ell_{\tau^*,t^*}(\tau^*,\hat{t}_2)
\end{equation}
for $\tau'\neq\tau^*$ with $\hat{t}_1$ and $\hat{t}_2$ estimated by maximizing \eqref{eq:profile_likelihood}, we have an inconsistency.

\section{Inconsistency of joint maximum likelihood}

\subsection{Bounding the likelihoods}

Our approach will be to seek bounds for the terms inside the maximization in \eqref{eq:log_likelihood_simplified} as
\begin{equation}
\label{eq:partial-likelihood}
\ell_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t) = H_{\tau^*,t^*}(\tau,t) + \ell^p_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t).
\end{equation}
We obtain an upper bound for the joint maximum of \eqref{eq:partial-likelihood}
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t) \le
    H_{\tau^*,t^*}(\tau^*,t^*)
    + \ell^p_{\tau^*,t^*}(\hat{\fullAncestralStateCategories},\tau,\hat{t})
$$
using Gibbs's inequality
$$
H_{\tau^*,t^*}(\tau,t) \le H_{\tau^*,t^*}(\tau^*,t^*)
$$
and
$$
\{\hat{\fullAncestralStateCategories},\hat{t}\} = \arg\max_{\{\fullAncestralStateCategories,t\}} \ \ell^p_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t).
$$
Similarly, we have a lower bound as
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau^*,t^*}(\fullAncestralStateCategories,\tau,t) \ge
    H_{\tau^*,t^*}(\tau,\hat{t})
    + \ell^p_{\tau^*,t^*}(\hat{\fullAncestralStateCategories},\tau,\hat{t}).
$$

% vvvv Remove these? I think they're obvious now, but maybe they can be made more explicit above?
\textbf{Argument for lower bound}: This makes intuitive sense, though may be difficult to show in general.
Can we not just say $\max_u f(u) + g(u)$ is greater than $f(u') + g(u')$ for any $u'$ that doesn't maximize $f(u) + g(u)$ just by definition?
There could be multiple maxima, but that's why we have greater than or equal to.
I think the only thing we'd need to show is that a maximum exists, but since $\{x,y,w\}$ are supported on a closed set this is certainly true.
I must be missing something.

\textbf{Argument for upper bound}: I think this is true mostly because $\max_u f(u) + g(u)$ should be less than $\max_u f(u) + \max_u g(u)$ by some triangle inequality argument.
If we were to actually maximize the full likelihood, we should get something smaller than maximizing some form of it that we consider by looking at the parts separately.
For a fixed $\{x^*, y^*\}$ we can calculate this upper bound directly---can we obtain it as a useful-looking function of these parameters in the general case?

\subsection{Parameter setting}

\begin{figure}
\centering
\begin{subfigure}{.45\linewidth}
\centering
\includegraphics[width=.95\textwidth]{farris_blank}
\caption[short]{Farris topology $\tau_1$}
\end{subfigure}
\begin{subfigure}{.45\linewidth}
\centering
\includegraphics[width=.95\textwidth]{felsenstein_blank}
\caption[short]{Felsenstein topology $\tau_2$}
\end{subfigure}
\caption{Two simple topologies}
\label{fig:farris-fels-top}
\end{figure}

Define the Farris topology $\tau_1$ and the Felsenstein topology $\tau_2$ as in Figure~\ref{fig:farris-fels-top}.
Call $t=\{x,y,w\}$ and $t^*=\{x,y,y\}$, i.e., $t^*$ is the case where the bottom three branches all share the same parameter, the classical construction of this topology.
The branch length parameters are such that the probability of a change in character along the top two branches is $p_x=1-2x$, with corresponding equalities for the other two branches.
Here, $\{p_x,p_y,p_w\}\in[0,1/2]^3$ and $\{x,y,w\}\in[0,1]^3$.

\textbf{Justification for estimand:} It might be worth arguing why this form of the estimand $t$ is necessary.
I think the idea is that for either of these topologies, any maximum obtained will occur where the top two and bottom two branches are equal, though not necessarily the middle branch.
This would be good to show explicitly.

Table~\ref{tab:sitepatprob} contains calculations of site pattern frequencies under these two topologies, calculated using the Hadamard transform approach outlined in 8.6 of Semple and Steel \cite{Semple2003-em}.
Table~\ref{tab:likelihoods} contains calculations of likelihood values for fixed site patterns and topologies, with the maximum values over ancestral state patterns noted.

\begin{table}
\centering
\begin{tabular}{|l|l|l|}
\multicolumn{3}{c}{Classical}\\
    \hline
$\sitePattern_j$   &$P(\sitePattern_j|\tau_1,t^*)$&$P(\sitePattern_j|\tau_2,t^*)$\\
    \hline
0000&$1+x^2+y^2+4xy^2+x^2y^2$&$1+2xy+2xy^2+x^2y+y^3+x^2y^2$\\
0001&$1+x^2-y^2-x^2y^2$&$1+x^2y-y^3-x^2y^2$\\
0010&$1-x^2+y^2-x^2y^2$&$1-x^2y+y^3-x^2y^2$\\
0100&$1+x^2-y^2-x^2y^2$&$1+x^2y-y^3-x^2y^2$\\
1000&$1-x^2+y^2-x^2y^2$&$1-x^2y+y^3-x^2y^2$\\
0011&$1-x^2-y^2+x^2y^2$&$1+2xy-2xy^2-x^2y-y^3+x^2y^2$\\
0101&$1+x^2+y^2-4xy^2+x^2y^2$&$1-2xy-2xy^2+x^2y+y^3+x^2y^2$\\
1001&$1-x^2-y^2+x^2y^2$&$1-2xy+2xy^2-x^2y-y^3+x^2y^2$\\
    \hline
\multicolumn{3}{c}{Modified}\\
    \hline
$\sitePattern_j$   &$P(\sitePattern_j|\tau_1,t)$&$P(\sitePattern_j|\tau_2,t)$\\
    \hline
0000&$1+x^2+y^2+4xyw+x^2y^2$&$1+2xy+2xyw+x^2w+y^2w+x^2y^2$\\
0001&$1+x^2-y^2-x^2y^2$&$1+x^2w-y^2w-x^2y^2$\\
0010&$1-x^2+y^2-x^2y^2$&$1-x^2w+y^2w-x^2y^2$\\
0100&$1+x^2-y^2-x^2y^2$&$1+x^2w-y^2w-x^2y^2$\\
1000&$1-x^2+y^2-x^2y^2$&$1-x^2w+y^2w-x^2y^2$\\
0011&$1-x^2-y^2+x^2y^2$&$1+2xy-2xyw-x^2w-y^2w+x^2y^2$\\
0101&$1+x^2+y^2-4xyw+x^2y^2$&$1-2xy-2xyw+x^2w+y^2w+x^2y^2$\\
1001&$1-x^2-y^2+x^2y^2$&$1-2xy+2xyw-x^2w-y^2w+x^2y^2$\\
    \hline
\end{tabular}
\caption{Site pattern probabilities.
All values are multiplied by $1/8$.}
\label{tab:sitepatprob}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l|ll|}
\multicolumn{3}{c}{$P(\ancestralStateCategory_j|\sitePattern_j,\tau_1,t)$}\\
\hline
& \multicolumn{2}{|c|}{$\ancestralStateCategory_j$}\\
    \hline
$\sitePattern_j$    &00                              &01\\
    \hline
0000&$(1+x)^2   (1+w)(1+y)^{2*}$          &$(1+x)^2   (1-w)(1-y)^2$\\
0001&$(1+x)^2   (1+w)(1+y)(1-y)^*$        &$(1+x)^2   (1-w)(1+y)(1-y)$\\
0010&$(1+x)^2   (1+w)(1+y)(1-y)^*$        &$(1+x)^2   (1-w)(1+y)(1-y)$\\
0100&$(1+x)(1-x)(1+w)(1+y)^{2*}$          &$(1+x)(1-x)(1-w)(1-y)^2$\\
1000&$(1+x)(1-x)(1+w)(1+y)^{2*}$          &$(1+x)(1-x)(1-w)(1-y)^2$\\
0011&$(1+x)(1-x)(1+w)(1+y)(1-y)^{\dagger}$&$(1+x)(1-x)(1-w)(1+y)(1-y)$\\
0101&$(1+x)^2   (1+w)(1-y)^{2\ddagger}$   &$(1+x)^2   (1-w)(1+y)^{2\ddagger}$\\
1001&$(1+x)(1-x)(1+w)(1+y)(1-y)^{\dagger}$&$(1+x)(1-x)(1-w)(1+y)(1-y)$\\
    \hline
    \hline
&10                           &11\\
    \hline
0000&$(1-x)^2   (1-w)(1+y)^2$     &$(1-x)^2   (1+w)(1-y)^2$\\
0001&$(1-x)^2   (1-w)(1+y)(1-y)$  &$(1-x)^2   (1+w)(1+y)(1-y)$\\
0010&$(1-x)^2   (1-w)(1+y)(1-y)$  &$(1-x)^2   (1+w)(1+y)(1-y)$\\
0100&$(1+x)(1-x)(1-w)(1+y)^2$     &$(1+x)(1-x)(1+w)(1-y)^2$\\
1000&$(1+x)(1-x)(1-w)(1+y)^2$     &$(1+x)(1-x)(1+w)(1-y)^2$\\
0011&$(1+x)(1-x)(1-w)(1+y)(1-y)$  &$(1+x)(1-x)(1+w)(1+y)(1-y)^{\dagger}$\\
0101&$(1-x)^2   (1-w)(1-y)^2$     &$(1-x)^2   (1+w)(1+y)^{2\ddagger}$\\
1001&$(1+x)(1-x)(1-w)(1+y)(1-y)$  &$(1+x)(1-x)(1+w)(1+y)(1-y)^{\dagger}$\\
    \hline
    \multicolumn{3}{c}{$P(\ancestralStateCategory_j|\sitePattern_j,\tau_2,t)$}\\
\hline
& \multicolumn{2}{|c|}{$\ancestralStateCategory_j$}\\
    \hline
$\sitePattern_j$    &00                              &01\\
    \hline
0000&$(1+x)^2   (1+w)(1+y)^{2*}$           &$(1+x)(1-x)(1-w)(1+y)(1-y)$\\
0001&$(1+x)^2   (1+w)(1+y)(1-y)^{\ddagger}$&$(1+x)(1-x)(1-w)(1+y)^{2\ddagger}$\\
0010&$(1+x)(1-x)(1+w)(1+y)^{2\ddagger}$    &$(1+x)^2   (1-w)(1+y)(1-y)^{\ddagger}$\\
0100&$(1+x)^2   (1+w)(1+y)(1-y)^{\ddagger}$&$(1+x)(1-x)(1-w)(1-y)^2$\\
1000&$(1+x)(1-x)(1+w)(1+y)^{2\ddagger}$    &$(1-x)^2   (1-w)(1+y)(1-y)$\\
0011&$(1+x)(1-x)(1+w)(1+y)(1-y)^{\ddagger}$&$(1+x)^2   (1-w)(1+y)^{2\ddagger}$\\
0101&$(1+x)^2   (1+w)(1-y)^{2\ddagger}$    &$(1+x)(1-x)(1-w)(1+y)(1-y)^{\ddagger}$\\
1001&$(1+x)(1-x)(1+w)(1+y)(1-y)^{\ddagger}$&$(1-x)^2   (1-w)(1+y)^{2\ddagger}$\\
    \hline
    \hline
&10                           &11\\
    \hline
0000&$(1+x)(1-x)(1-w)(1+y)(1-y)$             &$(1-x)^2   (1+w)(1-y)^2$\\
0001&$(1+x)(1-x)(1-w)(1-y)^2$                &$(1-x)^2   (1+w)(1+y)(1-y)$\\
0010&$(1-x)^2   (1-w)(1+y)(1-y)$             &$(1+x)(1-x)(1+w)(1-y)^2$\\
0100&$(1+x)(1-x)(1-w)(1+y)^{2\ddagger}$      &$(1-x)^2   (1+w)(1+y)(1-y)$\\
1000&$(1+x)^2   (1-w)(1+y)(1-y)^{\ddagger}$  &$(1+x)(1-x)(1+w)(1-y)^2$\\
0011&$(1-x)^2   (1-w)(1-y)^2$                &$(1+x)(1-x)(1+w)(1+y)(1-y)^{\ddagger}$\\
0101&$(1+x)(1-x)(1-w)(1+y)(1-y)^{\ddagger}$  &$(1-x)^2   (1+w)(1+y)^{2\ddagger}$\\
1001&$(1+x)^2   (1-w)(1-y)^{2\ddagger}$      &$(1+x)(1-x)(1+w)(1+y)(1-y)^{\ddagger}$\\
\hline
\end{tabular}
\caption{Likelihood calculations for all site patterns and internal states of Farris topology.
Maxima determined row-wise (i.e., by site pattern).
All values multiplied by $1/32$.
Key: $^*$ unique maximum value corresponding to unique internal state; $^\dagger$ unique maximum value corresponding to multiple internal states; $^\ddagger$ multiple maximum values corresponding to multiple internal states.}
\label{tab:likelihoods}
\end{table}

\subsubsection{Upper bound for Farris partial likelihood}

Assume $\tau^*=\tau_1$ and $t^*=\{x,y,y\}$.
To obtain an upper bound for the Farris partial likelihood---the terms in the top half of Table~\ref{tab:likelihoods}---we use the term $(1+x)^2(1+w)(1+y)^2$ for the $0101$ site pattern.
Since all cases have a $(1+x)^2$ term except $\{0100, 1000, 0011, 1001\}$, and all cases except $\{0001, 0010, 0011, 1001\}$ have a $(1+y)^2$, we can add and subtract the $\log$ of these terms weighted by each of their generating probabilities.
In other words, define
\begin{align*}
    a_{xy} &= P(0100|\tau=\tau_1,t=\{x,y,y\}) + P(1000|\tau=\tau_1,t=\{x,y,y\}) \\
           &\qquad + P(0011|\tau=\tau_1,t=\{x,y,y\}) + P(1001|\tau=\tau_1,t=\{x,y,y\})
\end{align*}
and
\begin{align*}
    b_{xy} &= P(1000|\tau=\tau_1,t=\{x,y,y\}) + P(0010|\tau=\tau_1,t=\{x,y,y\}) \\
           &\qquad + P(0011|\tau=\tau_1,t=\{x,y,y\}) + P(1001|\tau=\tau_1,t=\{x,y,y\}).
\end{align*}
Then the ancestral state maximizing the likelihood is $00$ for each site pattern and the partial likelihood is bounded above
\begin{align*}
    & \ell^p_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_1,\{x',y',w'\}) \\
    &\qquad \le (2-a_{xy})\log(1+x')+a_{xy}\log(1-x')+(2-b_{xy})\log(1+y')+b_{xy}\log(1-y')+\log(1+w') \\
    &\qquad \le (2-a_{xy})\log(2-a_{xy})+a_{xy}\log(a_{xy})+(2-b_{xy})\log(2-b_{xy})+b_{xy}\log(b_{xy})+\log(2) \\
    &\qquad \triangleq L^p_{\tau_1,\tau_1}(a_{xy}, b_{xy})
\end{align*}
where $a_{xy}$ and $b_{xy}$ are functions of the true generating branch parameters $\{x,y\}$.

\subsubsection{Lower bound for Felsenstein partial likelihood}

We construct a similar lower bound on the Felsenstein partial likelihood, though here we replace all $(1+w)$ terms with $(1-w)$.
Let
\begin{align*}
    c_{xy} &= P(0001|\tau=\tau_1,t=\{x,y,y\}) + P(0010|\tau=\tau_1,t=\{x,y,y\}) \\
           &\qquad + P(0100|\tau=\tau_1,t=\{x,y,y\}) + P(1000|\tau=\tau_1,t=\{x,y,y\})
\end{align*}
and
$$
    d_{xy} = P(0101|\tau=\tau_1,t=\{x,y,y\}) + P(1001|\tau=\tau_1,t=\{x,y,y\}).
$$
The lower bounds on the likelihoods in this case take one of six forms:
Since the maxima for pairs of lower bounds above each have a symmetry in $x$ and $y$, they are bounded below by one of
\textbf{TODO}: ancestral states where these likelihoods occur

\begin{align*}
    & \ell^p_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,\{x',y',w'\}) \\
    &\qquad \ge 2\log(1+x')+(2-c_{xy}-2d_{xy})\log(1+y')+(c_{xy}+2d_{xy})\log(1-y')+\log(1-w') \\
    &\qquad \ge 2\log(2)+(2-c_{xy}-2d_{xy})\log(2-c_{xy}-2d_{xy})+(c_{xy}+2d_{xy})\log(c_{xy}+2d_{xy}) \\
    &\qquad \triangleq L^{p,1}_{\tau_1,\tau_2}(c_{xy}, d_{xy}),
\end{align*}
\begin{align*}
    & \ell^p_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,\{x',y',w'\}) \\
    &\qquad \ge (2-2d_{xy})\log(1+x')+2d_{xy}\log(1-x') + (2-c_{xy})\log(1+y')+c_{xy}\log(1-y')+\log(1-w') \\
    &\qquad \ge (2-2d_{xy})\log(2-2d_{xy})+2d_{xy}\log(2d_{xy}) + (2-c_{xy})\log(2-c_{xy})+c_{xy}\log(c_{xy}) \\
    &\qquad \triangleq L^{p,2}_{\tau_1,\tau_2}(c_{xy}, d_{xy})
\end{align*}
or
\begin{align*}
    & \ell^p_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,\{x',y',w'\}) \\
    &\qquad \ge (2-d_{xy})\log(1+x')+d_{xy}\log(1-x') + (2-c_{xy}-d_{xy})\log(1+y')+(c_{xy}+d_{xy})\log(1-y')+\log(1-w') \\
    &\qquad \ge (2-d_{xy})\log(2-d_{xy})+d_{xy}\log(d_{xy}) + (2-c_{xy}-d_{xy})\log(2-c_{xy}-d_{xy})+(c_{xy}+d_{xy})\log(c_{xy}+d_{xy}) \\
    &\qquad \triangleq L^{p,3}_{\tau_1,\tau_2}(c_{xy}, d_{xy})
\end{align*}
where $c_{xy}$ and $d_{xy}$ are also functions of the true generating branch parameters $\{x,y\}$.

\textbf{Claim to prove}:
$$
L^{p,1}_{\tau_1,\tau_2}(c_{xy}, d_{xy}) \ge L^{p,2}_{\tau_1,\tau_2}(c_{xy}, d_{xy})
$$
and
$$
L^{p,1}_{\tau_1,\tau_2}(c_{xy}, d_{xy}) \ge L^{p,3}_{\tau_1,\tau_2}(c_{xy}, d_{xy}).
$$
I think we can use information theory results to show this.
It is definitely true---will work on it.

The values of $(x', y', w')$ maximizing $L^{p,1}_{\tau_1,\tau_2}(c_{xy}, d_{xy})$ are $(1, 1-c_{xy}-2d_{xy},0)$.

\subsubsection{Region of inconsistency}

We want to find values for $\{x,y\}$ where
$$
H_{\tau_1,\{x,y,y\}}(\tau_2,\{1, 1-c_{xy}-2d_{xy}, 0\}) + L^{p,1}_{\tau_1,\tau_2}(c_{xy},d_{xy}) \ge H_{\tau_1,\{x,y,y\}}(\tau_1,\{y, y, y\}) + L^{p}_{\tau_1,\tau_1}(a_{xy},b_{xy}).
$$
Since this is a single inequality in two variables, we can plot it analytically; we need the region where
\begin{align*}
    0 &\ge H_{\tau_1,\{x,y,y\}}(\tau_1,\{y, y, y\}) + L^{p}_{\tau_1,\tau_1}(a_{xy},b_{xy}) \\
      &\qquad - H_{\tau_1,\{x,y,y\}}(\tau_2,\{1, 1-c_{xy}-2d_{xy}, 0\}) - L^{p,1}_{\tau_1,\tau_2}(c_{xy},d_{xy}) \\
%
      &\qquad = 2(1+x^2-y^2-x^2y^2)\log(1+x^2-y^2-x^2y^2) \\
      &\qquad + 2(1-x^2+y^2-x^2y^2)\log(1-x^2+y^2-x^2y^2) \\
      &\qquad + 2(1-x^2-y^2+x^2y^2)\log(1-x^2-y^2+x^2y^2) \\
      &\qquad + (1+x^2+y^2+4xy^2+x^2y^2)\log(1+x^2+y^2+4xy^2+x^2y^2) \\
      &\qquad + (1+x^2+y^2-4xy^2+x^2y^2)\log(1+x^2+y^2-4xy^2+x^2y^2) \\
%
      &\qquad + (2-a_{xy})\log(2-a_{xy})+a_{xy}\log(a_{xy})+(2-b_{xy})\log(2-b_{xy})+b_{xy}\log(b_{xy})+\log(2) \\
%
      &\qquad - 2(1+x^2-y^2-x^2y^2)\log(1+x'^2w'-y'^2w'-x'^2y'^2) \\
      &\qquad - 2(1-x^2+y^2-x^2y^2)\log(1-x'^2w'+y'^2w'-x'^2y'^2) \\
      &\qquad - (1-x^2-y^2+x^2y^2)\log(1+2x'y'-2x'y'w'-x'^2w'-y'^2w'+x'^2y'^2) \\
      &\qquad - (1-x^2-y^2+x^2y^2)\log(1-2x'y'+2x'y'w'-x'^2w'-y'^2w'+x'^2y'^2) \\
      &\qquad - (1+x^2+y^2+4xy^2+x^2y^2)\log(1+2x'y'+2x'y'w'+x'^2w'+y'^2w'+x'^2y'^2) \\
      &\qquad - (1+x^2+y^2-4xy^2+x^2y^2)\log(1-2x'y'-2x'y'w'+x'^2w'+y'^2w'+x'^2y'^2) \\
%
      &\qquad - 2\log(2)-(2-c_{xy}-2d_{xy})\log(2-c_{xy}-2d_{xy})-(c_{xy}+2d_{xy})\log(c_{xy}+2d_{xy})
\end{align*}
where
$$
a_{xy} = b_{xy} = \frac{4-2x^2-2y^2}{8},
$$
$$
c_{xy} = \frac{4-4x^2y^2}{8},
$$
$$
d_{xy} = \frac{2-4xy^2+2x^2y^2}{8}
$$
and
$$
x' = 1, \ y' = 1-c_{xy}-2d_{xy}, \ w' = 0.
$$

The \texttt{sage} function in listing~\ref{list:sage} will generate Fig.~\ref{fig:inconsistency-farris}.

\begin{table}
    \begin{center}
\begin{verbatim}
var('x,y')
a = (4-2*x^2-2*y^2)/8
b = (4-2*x^2-2*y^2)/8
c = (4-4*x^2*y^2)/8
d = (2-4*x*y^2+2*x^2*y^2)/8
xp = 1.
yp = 1-c-2*d
wp = 0.

inconsistency = 2*(1+x^2-y^2-x^2*y^2)*log(1+x^2-y^2-x^2*y^2) \
    + 2*(1-x^2+y^2-x^2*y^2)*log(1-x^2+y^2-x^2*y^2) \
    + 2*(1-x^2-y^2+x^2*y^2)*log(1-x^2-y^2+x^2*y^2) \
    + (1+x^2+y^2+4*x*y^2+x^2*y^2)*log(1+x^2+y^2+4*x*y^2+x^2*y^2) \
    + (1+x^2+y^2-4*x*y^2+x^2*y^2)*log(1+x^2+y^2-4*x*y^2+x^2*y^2) \
    + (2-a)*log(2-a)+a*log(a)+(2-b)*log(2-b)+b*log(b)+log(2.) \
    - 2*(1+x^2-y^2-x^2*y^2)*log(1+xp^2*wp-yp^2*wp-xp^2*yp^2) \
    - 2*(1-x^2+y^2-x^2*y^2)*log(1-xp^2*wp+yp^2*wp-xp^2*yp^2) \
    - (1-x^2-y^2+x^2*y^2)*log(1+2*xp*yp-2*xp*yp*wp-xp^2*wp-yp^2*wp+xp^2*yp^2) \
    - (1-x^2-y^2+x^2*y^2)*log(1-2*xp*yp+2*xp*yp*wp-xp^2*wp-yp^2*wp+xp^2*yp^2) \
    - (1+x^2+y^2+4*x*y^2+x^2*y^2)*log(1+2*xp*yp+2*xp*yp*wp+xp^2*wp+yp^2*wp+xp^2*yp^2) \
    - (1+x^2+y^2-4*x*y^2+x^2*y^2)*log(1-2*xp*yp-2*xp*yp*wp+xp^2*wp+yp^2*wp+xp^2*yp^2) \
    - 2*log(2.)-(2-c-2*d)*log(2-c-2*d)-(c+2*d)*log(c+2*d)

incons_plot = implicit_plot(
    inconsistency(x,y)==0,
    (x,0,1),
    (y,0,1),
    axes_labels=['$x$', '$y$'],
    title='Region of inconsistency for Farris-generating topology',
    color='black'
)
\end{verbatim}
    \end{center}
\caption{Sage code to generate Fig.~\ref{fig:inconsistency-farris}}
\label{list:sage}
\end{table}

\begin{figure}
\centering
\includegraphics[width=.9\textwidth]{analytic-inconsistency}
\caption{
    Region of inconsistency.
    Due to the looseness of the upper and lower bounds, the parameters in the top right do not necessarily indicate consistency, though all parameters in the labeled region will result in an inconsistency.
}
\label{fig:inconsistency-farris}
\end{figure}

\paragraph{Example}

Set $\{x, y\} = \{0.25, 0.25\}$.
For a Farris zone generating topology, we have
$$
a_{xy} = b_{xy} = 0.46875
$$
resulting in
$$
L^{p}_{\tau_1,\tau_1}(a_{xy},b_{xy}) \approx -2.17803560694157
$$
and
$$
H_{\tau_1,\{x,y,y\}}(\tau_1,\{y, y, y\})  \approx -2.04470918734314.
$$
Computing the upper bound yields
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_1,t) \le -4.22274479428471
$$
and it remains to show that
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,t) \ge -4.22274479428471.
$$

For the same generating parameters,
$$
c_{xy} = 0.498046875, \ d_{xy} = 0.2431640625,
$$
resulting in
$$
L^{p,1}_{\tau_1,\tau_2}(c_{xy},d_{xy}) \approx -2.07968569223991
$$
and
$$
H_{\tau_1,\{x,y,y\}}(\tau_2,\{1, 1-c_{xy}-2d_{xy}, 0\}) \approx -2.07748833719921.
$$
The lower bound in this case becomes
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,t) \ge -4.22274479428471 \ge -4.22274479428471 \ge \max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_1,t)
$$
where site patterns are generated from the Farris zone topology.
Confirming, run \texttt{python}'s numerical optimization solver for $\{.25, .25\}$.
Since we are computing a constrained maximization, we can find a global maximum using basin hopping, and doing so yields
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_1,t) \approx -4.5101771294218045
$$
and
$$
\max_{\{t,\fullAncestralStateCategories\}} \ \ell_{\tau_1,\{x,y,y\}}(\fullAncestralStateCategories,\tau_2,t) \approx -4.1544859851260281.
$$
Woohoo!

\section{Discussion}

Neyman-Scott paradox.

Interesting that here we are simulating on the Farris tree and end up with the Felsenstein tree.
For maximum parsimony it's the opposite \cite{Felsenstein1978-rr}.
Discussion of number of parameters of each.

However, note that \cite{Siddall1998-hq} get things going the same way, although \cite{Swofford2001-hr} show that the problem is that they didn't simulate long enough sequences.

\bibliographystyle{plain}
\bibliography{joint_inf}

\end{document}
